{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fa81fce-ae6d-47dc-9086-993a63cffff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosave disabled\n"
     ]
    }
   ],
   "source": [
    "%autosave 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94145e53-404d-4531-8fce-e4738c5f0135",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-12 21:24:12.327239: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45df32ad-f3f8-4ee7-861b-1d9610f8dff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-03-06 21:38:20--  https://github.com/DataTalksClub/machine-learning-zoomcamp/releases/download/chapter7-model/xception_v4_large_08_0.894.h5\n",
      "140.82.112.3thub.com (github.com)... \n",
      "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/256401220/0156a400-0049-11eb-8490-c0d01b48ea8c?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250307%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250307T033820Z&X-Amz-Expires=300&X-Amz-Signature=e2c39568b21c23dc70420f10c3fe8e66fb95f70b335451e436967e6322f13393&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dxception_v4_large_08_0.894.h5&response-content-type=application%2Foctet-stream [following]\n",
      "--2025-03-06 21:38:20--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/256401220/0156a400-0049-11eb-8490-c0d01b48ea8c?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250307%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250307T033820Z&X-Amz-Expires=300&X-Amz-Signature=e2c39568b21c23dc70420f10c3fe8e66fb95f70b335451e436967e6322f13393&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dxception_v4_large_08_0.894.h5&response-content-type=application%2Foctet-stream\n",
      "185.199.108.133, 185.199.109.133, 185.199.110.133, ...busercontent.com)... \n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 86185888 (82M) [application/octet-stream]\n",
      "Saving to: ‘clothing-model.h5’\n",
      "\n",
      "clothing-model.h5   100%[===================>]  82.19M  6.02MB/s    in 18s     \n",
      "\n",
      "2025-03-06 21:38:39 (4.60 MB/s) - ‘clothing-model.h5’ saved [86185888/86185888]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/DataTalksClub/machine-learning-zoomcamp/releases/download/chapter7-model/xception_v4_large_08_0.894.h5 -O clothing-model.h5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e51d8be0-a618-4835-81b2-c144305fa294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.12.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fe32b12-42f1-426d-b106-8aa8d0470f77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.23.5'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "numpy.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ced9d77-90d1-4f7e-a9dd-66ba043733ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.11.0\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e4d0f9f-fe9a-4ebd-8ff9-1519e0410762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model = keras.models.load_model('clothing-model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40f90eba-0fd7-416c-8a6f-9c6d65c242ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-03-06 21:44:48--  http://bit.ly/mlbookcamp-pants\n",
      "67.199.248.10, 67.199.248.11 \n",
      "connected. to bit.ly (bit.ly)|67.199.248.10|:80... \n",
      "301 Moved Permanentlyaiting response... \n",
      "Location: https://raw.githubusercontent.com/alexeygrigorev/clothing-dataset-small/master/test/pants/4aabd82c-82e1-4181-a84d-d0c6e550d26d.jpg [following]\n",
      "--2025-03-06 21:44:48--  https://raw.githubusercontent.com/alexeygrigorev/clothing-dataset-small/master/test/pants/4aabd82c-82e1-4181-a84d-d0c6e550d26d.jpg\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 2606:50c0:8000::154, 2606:50c0:8002::154, 2606:50c0:8001::154, ...\n",
      "connected. to raw.githubusercontent.com (raw.githubusercontent.com)|2606:50c0:8000::154|:443... \n",
      "200 OKequest sent, awaiting response... \n",
      "Length: 23048 (23K) [image/jpeg]\n",
      "Saving to: ‘pants.jpg’\n",
      "\n",
      "pants.jpg           100%[===================>]  22.51K  --.-KB/s    in 0.08s   \n",
      "\n",
      "2025-03-06 21:44:48 (273 KB/s) - ‘pants.jpg’ saved [23048/23048]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download a image for testing\n",
    "!wget http://bit.ly/mlbookcamp-pants -O pants.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f1eb4cc-031d-41e3-9df2-2c608cb34615",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "\n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.xception import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "52628a04-27b7-443e-a3ed-20426e1e9670",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_img('pants.jpg', target_size = (299,299))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fe084581-bbbd-48e1-92ec-fc448107c8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert img from Image type to numpy array\n",
    "x = np.array(img)\n",
    "# Add one more dimension to x\n",
    "X = np.array([x])\n",
    "\n",
    "X = preprocess_input(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6e148988-b93f-4a19-acd0-328ec1f74f8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 299, 299, 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b43e0e58-024b-4d1c-9289-2da703c40108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 132ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "24b42178-d66f-4afe-a4da-b2f39dff7d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\n",
    "    'dress',\n",
    "    'hat',\n",
    "    'longsleeve',\n",
    "    'outwear',\n",
    "    'pants',\n",
    "    'shirt',\n",
    "    'shoes',\n",
    "    'shorts',\n",
    "    'skirt',\n",
    "    't-shirt'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0189f74d-573c-4bc8-84c9-e4297e78a493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dress': -1.8682896,\n",
       " 'hat': -4.7612457,\n",
       " 'longsleeve': -2.316982,\n",
       " 'outwear': -1.0625708,\n",
       " 'pants': 9.887158,\n",
       " 'shirt': -2.8124323,\n",
       " 'shoes': -3.666283,\n",
       " 'shorts': 3.2003586,\n",
       " 'skirt': -2.6023366,\n",
       " 't-shirt': -4.8350463}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(zip(classes, pred[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24614ed-3e59-48a4-866c-0e66ec506130",
   "metadata": {},
   "source": [
    "## Convert Keras to TF-Lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd06d75c-6ad0-49d8-86d4-65592ac9c74e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-11 23:11:56.770598: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,100]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-03-11 23:11:59.515357: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,100]\n",
      "\t [[{{node inputs}}]]\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 40). These functions will not be directly callable after loading.\n",
      "2025-03-11 23:12:02.424573: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2025-03-11 23:12:02.424659: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2025-03-11 23:12:05.937493: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2025-03-11 23:12:05.937514: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open('clothing-model.tflite', 'wb') as f_out:\n",
    "    f_out.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "83f411ea-3dae-4768-acf6-dfa0df1a0a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 360808\n",
      "-rw-r--r--  1 gabrielle  staff    80M Mar  6 22:52 clothing-mode.tflite\n",
      "-rw-r--r--  1 gabrielle  staff    82M Dec  7  2021 clothing-model.h5\n",
      "-rw-r--r--  1 gabrielle  staff    23K Mar  6 21:44 pants.jpg\n",
      "-rw-r--r--  1 gabrielle  staff    12K Mar  6 22:52 tensorflow-model.ipynb\n"
     ]
    }
   ],
   "source": [
    "!ls -lh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89744eec-3ac4-4162-89dd-0afc345903ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.lite as tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "523667a6-2938-4916-bbf5-9db3955a88a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Initialized TensorFlow Lite runtime.\n",
      "INFO: Applying 1 TensorFlow Lite delegate(s) lazily.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "VERBOSE: Replacing 104 node(s) with delegate (TfLiteXNNPackDelegate) node, yielding 1 partitions for the whole graph.\n",
      "INFO: Successfully applied the default TensorFlow Lite delegate indexed at 0.\n",
      " *NOTE*: because a delegate has been applied, the precision of computations should be unchanged, but the exact output tensor values may have changed. If such output values are checked in your code, like in your tests etc., please consider increasing error tolerance for the check.\n"
     ]
    }
   ],
   "source": [
    "interpreter = tflite.Interpreter(model_path = 'clothing-model.tflite')\n",
    "# Arrange memory resources for each step (input, process, output)\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "89797bc2-bc92-411b-b369-80030a643041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract index of input\n",
    "input_index = interpreter.get_input_details()[0]['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cc9ff2d5-13f5-49be-af28-fdde50aff1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract index of output\n",
    "output_index = interpreter.get_output_details()[0]['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4182d0d8-9194-467d-ad5a-0c219eabaea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在tensorflow lite中，模型的input和output是按照index管理\n",
    "# set_tensor()将input放在指定位置\n",
    "interpreter.set_tensor(input_index, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4460b18c-0288-4f49-8a16-4dec0eb79e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将input放在模型中进行处理，直到结束\n",
    "interpreter.invoke()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8546ee1a-033b-40b7-836b-ca91bf6ff80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_tensor()将output从指定位置取出\n",
    "pred = interpreter.get_tensor(output_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "44131ccd-8e35-4ee4-93e5-7feb2a39ec6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dress': -1.8682916,\n",
       " 'hat': -4.7612457,\n",
       " 'longsleeve': -2.316979,\n",
       " 'outwear': -1.0625672,\n",
       " 'pants': 9.8871565,\n",
       " 'shirt': -2.8124275,\n",
       " 'shoes': -3.666287,\n",
       " 'shorts': 3.2003636,\n",
       " 'skirt': -2.6023414,\n",
       " 't-shirt': -4.8350444}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(zip(classes, pred[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483c7ca0-d13d-43f1-b793-1362bf101bae",
   "metadata": {},
   "source": [
    "## Removing Tenmsorflow Dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c74eefc7-1380-419b-b962-ad06b604dcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_img来自于tensorflow.keras.preprocessing.image,而tensorflow lite是没有定义这个method的\n",
    "# 所以需要通过了解load_img的底层代码实现相同的作用\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "path = 'pants.jpg'\n",
    "with open(path, \"rb\") as f:\n",
    "    img = img.resize((299,299), Image.NEAREST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "63eccf65-69aa-4632-9654-51e57f1867a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_input(x):\n",
    "    x /= 127.5\n",
    "    x -= 1.0\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d6f72f24-3e0e-48bb-b65e-7ec1a6a4cbde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Applying 1 TensorFlow Lite delegate(s) lazily.\n",
      "VERBOSE: Replacing 104 node(s) with delegate (TfLiteXNNPackDelegate) node, yielding 1 partitions for the whole graph.\n",
      "INFO: Successfully applied the default TensorFlow Lite delegate indexed at 0.\n",
      " *NOTE*: because a delegate has been applied, the precision of computations should be unchanged, but the exact output tensor values may have changed. If such output values are checked in your code, like in your tests etc., please consider increasing error tolerance for the check.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-1.8682916, -4.7612457, -2.316979 , -1.0625672,  9.8871565,\n",
       "        -2.8124275, -3.666287 ,  3.2003636, -2.6023414, -4.8350444]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array(img, dtype='float32')\n",
    "X = np.array([x])\n",
    "X = preprocess_input(X)\n",
    "\n",
    "interpreter = tflite.Interpreter(model_path = 'clothing-model.tflite')\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_index = interpreter.get_input_details()[0]['index']\n",
    "output_index = interpreter.get_output_details()[0]['index']\n",
    "\n",
    "interpreter.set_tensor(input_index, X)\n",
    "interpreter.invoke()\n",
    "interpreter.get_tensor(output_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7e4c6291-bd18-49f7-9253-cfb8106c574c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dress': -1.8682916,\n",
       " 'hat': -4.7612457,\n",
       " 'longsleeve': -2.316979,\n",
       " 'outwear': -1.0625672,\n",
       " 'pants': 9.8871565,\n",
       " 'shirt': -2.8124275,\n",
       " 'shoes': -3.666287,\n",
       " 'shorts': 3.2003636,\n",
       " 'skirt': -2.6023414,\n",
       " 't-shirt': -4.8350444}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(zip(classes, pred[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ff7f80-88ca-4130-a39e-63b2a5c9bb33",
   "metadata": {},
   "source": [
    "## Simple Way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c3746ca1-d256-456d-a113-fcc4769903fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras-image-helper\n",
      "  Downloading keras_image_helper-0.0.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: numpy in /Users/gabrielle/opt/anaconda3/lib/python3.11/site-packages (from keras-image-helper) (1.23.5)\n",
      "Requirement already satisfied: pillow in /Users/gabrielle/opt/anaconda3/lib/python3.11/site-packages (from keras-image-helper) (11.1.0)\n",
      "Downloading keras_image_helper-0.0.1-py3-none-any.whl (4.6 kB)\n",
      "Installing collected packages: keras-image-helper\n",
      "Successfully installed keras-image-helper-0.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install keras-image-helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4c05b024-b4f5-4000-8a45-8e8955e597ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_image_helper import create_preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "be910985-4eb2-4d09-9e79-73d961c74308",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = create_preprocessor('xception', target_size = (299,299))\n",
    "\n",
    "url = 'http://bit.ly/mlbookcamp-pants'\n",
    "X = preprocessor.from_url(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a194ce2e-82e5-4d33-84cf-7845c15631a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dress': -1.8682916,\n",
       " 'hat': -4.7612457,\n",
       " 'longsleeve': -2.316979,\n",
       " 'outwear': -1.0625672,\n",
       " 'pants': 9.8871565,\n",
       " 'shirt': -2.8124275,\n",
       " 'shoes': -3.666287,\n",
       " 'shorts': 3.2003636,\n",
       " 'skirt': -2.6023414,\n",
       " 't-shirt': -4.8350444}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpreter.set_tensor(input_index, X)\n",
    "interpreter.invoke()\n",
    "interpreter.get_tensor(output_index)\n",
    "\n",
    "dict(zip(classes, pred[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9840856d-c5cc-41d9-a501-3a8144c93c18",
   "metadata": {},
   "source": [
    "## Download Tensorflow Lite Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "03b88b22-7d43-44a0-963e-d45df609b761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement tflite-runtime (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for tflite-runtime\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install --extra-index-url https://google-coral.github.io/py-repo/ tflite_runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f34db2-be78-4841-b795-eb7bb1ecd564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead of dowloading full tensorflow package to use tensorflow lite\n",
    "# we can directly download tensorflow lite package from the link above\n",
    "import tflite_runtime.interpreter as tflite"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
